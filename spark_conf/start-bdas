#!/bin/bash

cp /root/slaves $SPARK_CONF_DIR
cp /root/slaves $HADOOP_CONF_DIR

mkdir -p /data/hadoop/hdfs/nn
mkdir -p /data/hadoop/hdfs/snn
mkdir -p /data/hadoop/hdfs/dnn

hdfs namenode -format

start-dfs.sh
#start-yarn.sh

hdfs dfs -mkdir /user
hdfs dfs -mkdir /user/root

/usr/local/spark/sbin/start-all.sh
